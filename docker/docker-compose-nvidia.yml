version: '3'

services:
    stylecam:
        container_name: stylecam_container
        stdin_open: true # docker run -i
        tty: true
        privileged: true  # Todo maybe with new appraoch not needed
        build:
            context: ../
            dockerfile: ./docker/Dockerfile
        shm_size: 1g
        devices:
            - /dev/video0:/dev/video0 # TODO USER replace with your video input device before the :
            - /dev/uinput:/dev/uinput
        runtime: nvidia
        volumes:
            - ${STYLE_TRANSFER_MODEl_PATH}:/stylecam/data/style_transfer_models
        environment:
            #            - DISPLAY=${DISPLAY}
            #            - PYNPUT_BACKEND_MOUSE=dummy
            #            - PYNPUT_BACKEND_KEYBOARD=uinput
            #              TODO USER adapt parameters. An explanation to each parameter can be found in ../src/main.py
            - STYLE_TRANSFER_MODEl_PATH=./data/style_transfer_models
              #Directory which (subdirectories) contains saved
              #style transfer networks. Have to end with '.model' or '.pth'.
            #Own styles created with https://github.com/pytorch/examples/tree/master/fast_neural_style can be used.
            - STYLE_SCALE_FACTOR=0.7
            #scale factor of the image sent the neural network
            - NOISE_SUPRESSING_FACTOR=25
            #higher values reduce noise introduced by the style transfer but might lead to skewed human faces

        network_mode: host

        #entrypoint: /stylecam/entryscript.sh
        entrypoint: /bin/bash
