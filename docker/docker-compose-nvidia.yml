version: '3'

services:
    stylecam:
        container_name: stylecam_container
        stdin_open: true # docker run -i
        tty: true
        build:
            context: ../
            dockerfile: ./docker/Dockerfile
        shm_size: 1g
        devices:
            - /dev/video0:/dev/video0 # TODO USER replace with your video input device before the :
            - /dev/video12:/dev/video12
            - /dev/video13:/dev/video13
        runtime: nvidia
        volumes:
            - ${STYLE_TRANSFER_MODEl_PATH}:/stylecam/data/style_transfer_models
        environment:
            # TODO USER adapt parameters. An explanation to each parameter can be found in ../src/main.py
            - STYLE_TRANSFER_MODEl_PATH=./data/style_transfer_models
              #Directory which (subdirectories) contains saved
            #style transfer networks. Have to end with '.model' or '.pth'.
            #Own styles created with https://github.com/pytorch/examples/tree/master/fast_neural_style can be used.
            - STYLE_SCALE_FACTOR=0.7
            #scale factor of the image sent the neural network
            - NOISE_SUPRESSING_FACTOR=25
            #higher values reduce noise introduced by the style transfer but might lead to skewed human faces

        network_mode: host

        entrypoint: /stylecam/entryscript.sh
        #entrypoint: /bin/bash
